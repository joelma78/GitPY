{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgNoI94aulrXPiMDCA2ihn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joelma78/GitPY/blob/main/IMC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Notebook completo: Classificação de IMC com Rede Neural (MLP)\n",
        "\n",
        "# 1. Importação das bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from tensorflow.keras.models import Sequential, load_model # Moved load_model here\n",
        "from tensorflow.keras.layers import Dense\n",
        "import gradio as gr\n",
        "import os\n",
        "\n",
        "# 2. Leitura do dataset\n",
        "# Substitua o caminho abaixo pelo caminho do seu arquivo dadosimc.csv\n",
        "dataset_path = '/content/dadosimc.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "df.head()\n",
        "\n",
        "# 3. Limpeza e exploração dos dados\n",
        "# Verificar valores nulos\n",
        "df.isnull().sum()\n",
        "\n",
        "# Informações gerais do dataset\n",
        "df.info()\n",
        "\n",
        "# Estatísticas descritivas\n",
        "df.describe()\n",
        "\n",
        "# 4. Criação da variável alvo (classificação do IMC)\n",
        "def classificar_imc(imc):\n",
        "    if imc < 18.5:\n",
        "        return 'baixo peso'\n",
        "    elif imc < 25:\n",
        "        return 'normal'\n",
        "    elif imc < 30:\n",
        "        return 'sobrepeso'\n",
        "    else:\n",
        "        return 'obesidade'\n",
        "\n",
        "df['imc_categoria'] = df['imc'].apply(classificar_imc)\n",
        "df['imc_categoria'].value_counts()\n",
        "\n",
        "# Filter out rows where peso or altura are 0\n",
        "df = df[(df['peso'] > 0) & (df['altura'] > 0)].copy()\n",
        "\n",
        "\n",
        "# 5. Pré-processamento\n",
        "# Codificar a variável categórica 'sexo'\n",
        "le_sexo = LabelEncoder()\n",
        "df['sexo_encoded'] = le_sexo.fit_transform(df['sexo'])\n",
        "\n",
        "# Encode the target variable\n",
        "le_imc = LabelEncoder()\n",
        "le_imc.fit(df['imc_categoria'])\n",
        "\n",
        "\n",
        "# Selecionar features e alvo\n",
        "X = df[['idade', 'sexo_encoded', 'peso', 'altura']]\n",
        "y = df['imc_categoria']\n",
        "\n",
        "\n",
        "# Divisão em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Normalização das variáveis numéricas\n",
        "scaler = StandardScaler()\n",
        "X_train[['idade','peso','altura']] = scaler.fit_transform(X_train[['idade','peso','altura']])\n",
        "X_test[['idade','peso','altura']] = scaler.transform(X_test[['idade','peso','altura']])\n",
        "\n",
        "# Transformar y em valores numéricos para a rede neural\n",
        "y_train_enc = le_imc.transform(y_train)\n",
        "y_test_enc = le_imc.transform(y_test)\n",
        "\n",
        "# 6. Construção da rede neural (MLP)\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(8, activation='relu'),\n",
        "    Dense(len(le_imc.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Treinamento do modelo\n",
        "model.fit(X_train, y_train_enc, epochs=30, batch_size=8, verbose=1)\n",
        "\n",
        "# Salvar o modelo treinado no mesmo diretório do dataset\n",
        "model_save_path = os.path.join(os.path.dirname(dataset_path), 'modelo_imc_mlp.h5')\n",
        "model.save(model_save_path)\n",
        "\n",
        "\n",
        "# 7. Avaliação do modelo\n",
        "y_pred_enc = np.argmax(model.predict(X_test), axis=1)\n",
        "\n",
        "print(\"Acurácia:\", accuracy_score(y_test_enc, y_pred_enc))\n",
        "print(\"Matriz de Confusão:\\n\", confusion_matrix(y_test_enc, y_pred_enc))\n",
        "print(\"Classification Report:\\n\", classification_report(y_test_enc, y_pred_enc, target_names=le_imc.classes_))\n",
        "\n",
        "# 8. App interativo com Gradio\n",
        "\n",
        "# Salvando o modelo treinado\n",
        "loaded_model = load_model(model_save_path)\n",
        "\n",
        "def prever_imc_categoria_nn_loaded(idade, sexo, peso, altura):\n",
        "    sexo_num = le_sexo.transform([sexo])[0]\n",
        "    df_temp = pd.DataFrame([[idade, sexo_num, peso, altura]], columns=['idade','sexo_encoded','peso','altura'])\n",
        "    df_temp[['idade','peso','altura']] = scaler.transform(df_temp[['idade','peso','altura']])\n",
        "    pred_enc = np.argmax(loaded_model.predict(df_temp), axis=1)[0]\n",
        "    categoria = le_imc.inverse_transform([pred_enc])[0]\n",
        "    imc_real = peso / (altura ** 2)\n",
        "    return f\"IMC calculado: {imc_real:.2f}\\nCategoria prevista: {categoria}\"\n",
        "\n",
        "gr_interface = gr.Interface(\n",
        "    fn=prever_imc_categoria_nn_loaded, # Use the new function\n",
        "    inputs=[\n",
        "        gr.Number(label=\"Idade\"),\n",
        "        gr.Dropdown(choices=df['sexo'].unique().tolist(), label=\"Sexo\"),\n",
        "        gr.Number(label=\"Peso (kg)\"),\n",
        "        gr.Number(label=\"Altura (m)\")\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Resultado\"),\n",
        "    title=\"Previsão de Categoria de IMC \",\n",
        "    description=\"Entre com seus dados\"\n",
        ")\n",
        "\n",
        "gr_interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3x0EDXbCzLIv",
        "outputId": "19cc9c52-715e-416e-d8da-214eb1e6b6a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 300 entries, 0 to 299\n",
            "Data columns (total 5 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   idade   300 non-null    int64  \n",
            " 1   sexo    300 non-null    object \n",
            " 2   peso    300 non-null    float64\n",
            " 3   altura  300 non-null    float64\n",
            " 4   imc     300 non-null    float64\n",
            "dtypes: float64(3), int64(1), object(1)\n",
            "memory usage: 11.8+ KB\n",
            "Epoch 1/30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2655 - loss: 1.3489\n",
            "Epoch 2/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3891 - loss: 1.2718 \n",
            "Epoch 3/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4914 - loss: 1.2876 \n",
            "Epoch 4/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5362 - loss: 1.2317\n",
            "Epoch 5/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6807 - loss: 1.1134 \n",
            "Epoch 6/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6738 - loss: 1.0846 \n",
            "Epoch 7/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6448 - loss: 1.0448 \n",
            "Epoch 8/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6911 - loss: 1.0171 \n",
            "Epoch 9/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7210 - loss: 0.9726 \n",
            "Epoch 10/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6831 - loss: 0.9391 \n",
            "Epoch 11/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6619 - loss: 0.9599 \n",
            "Epoch 12/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.8991 \n",
            "Epoch 13/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6892 - loss: 0.8723 \n",
            "Epoch 14/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6882 - loss: 0.8508 \n",
            "Epoch 15/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7457 - loss: 0.7650 \n",
            "Epoch 16/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7647 - loss: 0.7223 \n",
            "Epoch 17/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7601 - loss: 0.7389 \n",
            "Epoch 18/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7121 - loss: 0.8205 \n",
            "Epoch 19/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7459 - loss: 0.7276 \n",
            "Epoch 20/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7252 - loss: 0.7212 \n",
            "Epoch 21/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7704 - loss: 0.6886\n",
            "Epoch 22/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7847 - loss: 0.6488\n",
            "Epoch 23/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8219 - loss: 0.6092\n",
            "Epoch 24/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7931 - loss: 0.6515\n",
            "Epoch 25/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8241 - loss: 0.5952\n",
            "Epoch 26/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7916 - loss: 0.6122\n",
            "Epoch 27/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7920 - loss: 0.5983\n",
            "Epoch 28/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8275 - loss: 0.5869\n",
            "Epoch 29/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7845 - loss: 0.5958\n",
            "Epoch 30/30\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8345 - loss: 0.5623\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
            "Acurácia: 0.8076923076923077\n",
            "Matriz de Confusão:\n",
            " [[15  2  0  0]\n",
            " [ 1 11  0  3]\n",
            " [ 0  0 10  0]\n",
            " [ 0  2  2  6]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  baixo peso       0.94      0.88      0.91        17\n",
            "      normal       0.73      0.73      0.73        15\n",
            "   obesidade       0.83      1.00      0.91        10\n",
            "   sobrepeso       0.67      0.60      0.63        10\n",
            "\n",
            "    accuracy                           0.81        52\n",
            "   macro avg       0.79      0.80      0.80        52\n",
            "weighted avg       0.81      0.81      0.81        52\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b831a5ab02dc70e0d3.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b831a5ab02dc70e0d3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CVTEPGOAzLLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kP6EKXazzLNI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}